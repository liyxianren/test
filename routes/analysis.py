from flask import Blueprint, request, jsonify
from flask_jwt_extended import jwt_required, get_jwt_identity
from models import EmotionAnalysis, EmotionDiary, db
from datetime import datetime
import json
import os
import re
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
import sys
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆç¡®ä¿åœ¨standaloneæµ‹è¯•æ—¶ä¹Ÿèƒ½å·¥ä½œï¼‰
load_dotenv()

# å¯¼å…¥æ™ºè°±AI SDK
try:
    from zhipuai import ZhipuAI
except ImportError:
    ZhipuAI = None
    print("è­¦å‘Š: æœªå®‰è£… zhipuai åŒ…ï¼ŒChatGLMåŠŸèƒ½å°†ä¸å¯ç”¨", file=sys.stderr)

# å¯¼å…¥Promptæ¨¡æ¿
try:
    sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
    from prompts.chatglm_prompts import (
        get_user_friendly_prompt,
        get_game_data_prompt,
        get_system_prompt
    )
except ImportError:
    print("è­¦å‘Š: æœªæ‰¾åˆ°chatglm_promptsæ¨¡å—ï¼Œä½¿ç”¨é»˜è®¤Prompt", file=sys.stderr)
    get_user_friendly_prompt = None
    get_game_data_prompt = None
    get_system_prompt = None

bp = Blueprint('analysis', __name__)

class EmotionAnalysisService:
    """æƒ…ç»ªåˆ†ææœåŠ¡ç±»"""

    def __init__(self):
        self.coze_api_key = os.getenv('COZE_API_KEY')
        self.coze_bot_id = os.getenv('COZE_BOT_ID')
        self.coze_base_url = os.getenv('COZE_BASE_URL', 'https://api.coze.com')
        self.qwen_api_key = os.getenv('QWEN_API_KEY')
        self.qwen_model = os.getenv('QWEN_MODEL_NAME', 'qwen-turbo')

        # æ™ºè°±AI ChatGLMé…ç½®
        self.zhipu_api_key = os.getenv('ZHIPU_API_KEY')
        self.zhipu_model = os.getenv('ZHIPU_MODEL_NAME', 'glm-4-flash')  # ä¿®æ­£é»˜è®¤æ¨¡å‹å
        self.zhipu_client = None

        if self.zhipu_api_key and ZhipuAI:
            try:
                self.zhipu_client = ZhipuAI(api_key=self.zhipu_api_key)
                print(f"[æˆåŠŸ] æ™ºè°±AIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {self.zhipu_model}", file=sys.stderr)
            except Exception as e:
                print(f"[å¤±è´¥] æ™ºè°±AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}", file=sys.stderr)
                self.zhipu_client = None
        else:
            if not self.zhipu_api_key:
                print("[è­¦å‘Š] æœªè®¾ç½® ZHIPU_API_KEY ç¯å¢ƒå˜é‡", file=sys.stderr)
            if not ZhipuAI:
                print("[è­¦å‘Š] æœªå®‰è£… zhipuai åŒ…ï¼Œè¯·è¿è¡Œ: pip install zhipuai", file=sys.stderr)

    def analyze_with_coze(self, text):
        """ä½¿ç”¨COZE APIè¿›è¡Œæƒ…ç»ªåˆ†æ"""
        if not self.coze_api_key or not self.coze_bot_id:
            return None

        try:
            # æ„å»ºè¯·æ±‚æ•°æ®
            headers = {
                'Authorization': f'Bearer {self.coze_api_key}',
                'Content-Type': 'application/json'
            }

            payload = {
                'bot_id': self.coze_bot_id,
                'user_id': 'cbt_diary_user',
                'query': f"è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…ç»ªï¼š{text}",
                'stream': False
            }

            response = requests.post(
                f'{self.coze_base_url}/v1/chat/completions',
                headers=headers,
                json=payload,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                return self.parse_coze_response(result)
            else:
                print(f"COZE APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                return None

        except Exception as e:
            print(f"COZE APIè°ƒç”¨å¼‚å¸¸: {str(e)}")
            return None

    def analyze_with_qwen(self, text):
        """ä½¿ç”¨QWENæ¨¡å‹è¿›è¡Œæƒ…ç»ªåˆ†æ"""
        if not self.qwen_api_key:
            return None

        try:
            headers = {
                'Authorization': f'Bearer {self.qwen_api_key}',
                'Content-Type': 'application/json'
            }

            # æ„å»ºæƒ…ç»ªåˆ†ææç¤ºè¯
            prompt = f"""
            è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œæƒ…ç»ªåˆ†æï¼Œè¿”å›JSONæ ¼å¼çš„ç»“æœï¼š

            æ–‡æœ¬å†…å®¹ï¼š"{text}"

            è¯·åˆ†æä»¥ä¸‹å†…å®¹å¹¶è¿”å›JSONæ ¼å¼ï¼š
            {{
                "overall_emotion": "ä¸»è¦æƒ…ç»ªï¼ˆhappy, sad, angry, anxious, calm, neutralç­‰ï¼‰",
                "emotion_intensity": æƒ…ç»ªå¼ºåº¦ï¼ˆ0.0-1.0ï¼‰,
                "emotion_dimensions": {{
                    "valence": æƒ…ç»ªæ•ˆä»·ï¼ˆ-1.0åˆ°1.0ï¼Œè´Ÿå€¼è¡¨ç¤ºè´Ÿé¢æƒ…ç»ªï¼Œæ­£å€¼è¡¨ç¤ºæ­£é¢æƒ…ç»ªï¼‰,
                    "arousal": å”¤é†’åº¦ï¼ˆ0.0-1.0ï¼Œè¡¨ç¤ºæƒ…ç»ªçš„æ¿€çƒˆç¨‹åº¦ï¼‰,
                    "dominance": æ§åˆ¶åº¦ï¼ˆ0.0-1.0ï¼Œè¡¨ç¤ºå¯¹æƒ…ç»ªçš„æ§åˆ¶æ„Ÿï¼‰
                }},
                "key_words": ["å…³é”®è¯1", "å…³é”®è¯2", ...],
                "confidence_score": ç½®ä¿¡åº¦ï¼ˆ0.0-1.0ï¼‰
            }}
            """

            payload = {
                'model': self.qwen_model,
                'input': {
                    'messages': [
                        {
                            'role': 'system',
                            'content': 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æƒ…ç»ªåˆ†æåŠ©æ‰‹ï¼Œè¯·å‡†ç¡®åˆ†ææ–‡æœ¬ä¸­çš„æƒ…ç»ªçŠ¶æ€ã€‚'
                        },
                        {
                            'role': 'user',
                            'content': prompt
                        }
                    ]
                },
                'parameters': {
                    'result_format': 'message'
                }
            }

            response = requests.post(
                'https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generate',
                headers=headers,
                json=payload,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                return self.parse_qwen_response(result)
            else:
                print(f"QWEN APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                return None

        except Exception as e:
            print(f"QWEN APIè°ƒç”¨å¼‚å¸¸: {str(e)}")
            return None

    def parse_coze_response(self, response_data):
        """è§£æCOZE APIå“åº”"""
        try:
            # è¿™é‡Œéœ€è¦æ ¹æ®COZE APIçš„å®é™…å“åº”æ ¼å¼è¿›è¡Œè§£æ
            # å‡è®¾è¿”å›çš„æ˜¯æ–‡æœ¬æ ¼å¼çš„æƒ…ç»ªåˆ†æç»“æœ
            content = response_data.get('choices', [{}])[0].get('message', {}).get('content', '')

            # ç®€å•çš„æƒ…ç»ªè¯†åˆ«é€»è¾‘
            emotions = {
                'happy': ['å¼€å¿ƒ', 'å¿«ä¹', 'é«˜å…´', 'æ„‰å¿«', 'æ»¡è¶³'],
                'sad': ['éš¾è¿‡', 'æ‚²ä¼¤', 'æ²®ä¸§', 'å¤±è½', 'ç—›è‹¦'],
                'angry': ['ç”Ÿæ°”', 'æ„¤æ€’', 'æ¼ç«', 'æ°”æ„¤', 'æš´èº'],
                'anxious': ['ç„¦è™‘', 'æ‹…å¿ƒ', 'ç´§å¼ ', 'ä¸å®‰', 'ææƒ§'],
                'calm': ['å¹³é™', 'å®é™', 'å®‰è¯¦', 'æ”¾æ¾', 'èˆ’é€‚']
            }

            detected_emotion = 'neutral'
            confidence = 0.5

            for emotion, keywords in emotions.items():
                for keyword in keywords:
                    if keyword in content:
                        detected_emotion = emotion
                        confidence = 0.7
                        break

            return {
                'overall_emotion': detected_emotion,
                'emotion_intensity': 0.6,
                'emotion_dimensions': {
                    'valence': 0.0,
                    'arousal': 0.5,
                    'dominance': 0.5
                },
                'key_words': self.extract_keywords(content),
                'confidence_score': confidence
            }

        except Exception as e:
            print(f"COZEå“åº”è§£æå¤±è´¥: {str(e)}")
            return None

    def parse_qwen_response(self, response_data):
        """è§£æQWEN APIå“åº”"""
        try:
            content = response_data.get('output', {}).get('choices', [{}])[0].get('message', {}).get('content', '')

            # å°è¯•è§£æJSONæ ¼å¼
            import json
            try:
                result = json.loads(content)
                return result
            except json.JSONDecodeError:
                # å¦‚æœæ— æ³•è§£æJSONï¼Œä½¿ç”¨å¤‡ç”¨è§£ææ–¹æ³•
                return self.parse_text_emotion(content)

        except Exception as e:
            print(f"QWENå“åº”è§£æå¤±è´¥: {str(e)}")
            return None

    def parse_text_emotion(self, text):
        """ä»æ–‡æœ¬ä¸­è§£ææƒ…ç»ªä¿¡æ¯"""
        emotions = {
            'happy': ['å¼€å¿ƒ', 'å¿«ä¹', 'é«˜å…´', 'æ„‰å¿«', 'æ»¡è¶³', 'å¹¸ç¦'],
            'sad': ['éš¾è¿‡', 'æ‚²ä¼¤', 'æ²®ä¸§', 'å¤±è½', 'ç—›è‹¦', 'ä¼¤å¿ƒ'],
            'angry': ['ç”Ÿæ°”', 'æ„¤æ€’', 'æ¼ç«', 'æ°”æ„¤', 'æš´èº', 'æ°”æ„¤'],
            'anxious': ['ç„¦è™‘', 'æ‹…å¿ƒ', 'ç´§å¼ ', 'ä¸å®‰', 'ææƒ§', 'å®³æ€•'],
            'calm': ['å¹³é™', 'å®é™', 'å®‰è¯¦', 'æ”¾æ¾', 'èˆ’é€‚', 'å®‰å¿ƒ']
        }

        # ç®€å•çš„æƒ…ç»ªè¯†åˆ«
        emotion_scores = {}
        for emotion, keywords in emotions.items():
            score = sum(1 for keyword in keywords if keyword in text)
            emotion_scores[emotion] = score

        # æ‰¾å‡ºå¾—åˆ†æœ€é«˜çš„æƒ…ç»ª
        max_emotion = max(emotion_scores.items(), key=lambda x: x[1])
        detected_emotion = max_emotion[0] if max_emotion[1] > 0 else 'neutral'

        return {
            'overall_emotion': detected_emotion,
            'emotion_intensity': min(0.9, max_emotion[1] * 0.3),
            'emotion_dimensions': {
                'valence': 0.0,
                'arousal': 0.5,
                'dominance': 0.5
            },
            'key_words': self.extract_keywords(text),
            'confidence_score': min(0.9, max_emotion[1] * 0.2 + 0.3)
        }

    def extract_keywords(self, text):
        """æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–
        common_words = ['çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™']

        import re
        words = re.findall(r'[\u4e00-\u9fff]+', text)
        word_freq = {}

        for word in words:
            if len(word) >= 2 and word not in common_words:
                word_freq[word] = word_freq.get(word, 0) + 1

        # è¿”å›é¢‘ç‡æœ€é«˜çš„å‰10ä¸ªè¯
        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        return [word for word, freq in sorted_words[:10]]

    def generate_emotion_mapping(self, emotion_data):
        """ç”Ÿæˆæƒ…ç»ª-æ¸¸æˆæ˜ å°„é…ç½®"""
        emotion = emotion_data.get('overall_emotion', 'neutral')
        intensity = emotion_data.get('emotion_intensity', 0.5)

        # æ¸¸æˆéš¾åº¦æ˜ å°„
        difficulty_mapping = {
            'happy': 0.7,
            'sad': 1.2,
            'angry': 1.4,
            'anxious': 1.3,
            'calm': 0.8,
            'neutral': 1.0
        }

        base_difficulty = difficulty_mapping.get(emotion, 1.0)
        final_difficulty = base_difficulty * (0.8 + intensity * 0.4)

        # è§’è‰²å±æ€§å½±å“
        character_effects = {
            'speed': 1.0,
            'strength': 1.0,
            'intelligence': 1.0
        }

        if emotion == 'sad':
            character_effects['speed'] = 0.8
            character_effects['strength'] = 0.9
        elif emotion == 'angry':
            character_effects['strength'] = 1.2
            character_effects['intelligence'] = 0.9
        elif emotion == 'anxious':
            character_effects['speed'] = 1.1
            character_effects['intelligence'] = 0.8
        elif emotion == 'happy':
            character_effects['speed'] = 1.1
            character_effects['intelligence'] = 1.1

        economy_modifiers = self._calculate_game_projection({
            'overall_emotion': emotion,
            'emotion_intensity': intensity,
            'valence_score': self._emotion_to_valence(emotion),
            'trigger_summary': ''
        })

        return {
            'difficulty_modifier': final_difficulty,
            'character_effects': character_effects,
            'scenario_recommendations': self.get_scenario_recommendations(emotion),
            'cbt_challenges': self.generate_cbt_challenges(emotion),
            'economy_modifiers': economy_modifiers
        }

    def get_scenario_recommendations(self, emotion):
        """æ ¹æ®æƒ…ç»ªæ¨èæ¸¸æˆåœºæ™¯"""
        scenarios = {
            'happy': ['é˜³å…‰è‰åŸ', 'å½©è™¹å±±è°·', 'æ¬¢ä¹åŸå ¡'],
            'sad': ['å®é™æ¹–æ³Š', 'æœˆå…‰æ£®æ—', 'æ¸©æš–å°å±‹'],
            'angry': ['å¹³é™æµ·å²¸', 'ç¦…æ„èŠ±å›­', 'å†¥æƒ³ç©ºé—´'],
            'anxious': ['è½»æ¾æµ·æ»©', 'èˆ’ç¼“æ¸©æ³‰', 'å®‰é™å›¾ä¹¦é¦†'],
            'calm': ['ç¦…æ„åº­é™¢', 'å¹³é™æ¹–é¢', 'å’Œè°èŠ±å›­']
        }

        return scenarios.get(emotion, ['ç¥ç§˜å²›å±¿'])

    def generate_cbt_challenges(self, emotion):
        """ç”ŸæˆCBTæŒ‘æˆ˜ä»»åŠ¡"""
        challenges = {
            'sad': [
                'è¯†åˆ«è´Ÿé¢æ€ç»´æ¨¡å¼',
                'å¯»æ‰¾ç§¯æè¯æ®',
                'é‡æ„æ¶ˆææƒ³æ³•',
                'ç»ƒä¹ æ„Ÿæ©æ—¥è®°'
            ],
            'angry': [
                'æƒ…ç»ªè¯†åˆ«ç»ƒä¹ ',
                'æ„¤æ€’ç®¡ç†æŠ€å·§',
                'æ¢ä½æ€è€ƒç»ƒä¹ ',
                'æ”¾æ¾è®­ç»ƒ'
            ],
            'anxious': [
                'ç„¦è™‘æºè¯†åˆ«',
                'ç°å®æ€§æ£€éªŒ',
                'åº”å¯¹ç­–ç•¥åˆ¶å®š',
                'æ­£å¿µç»ƒä¹ '
            ],
            'happy': [
                'ç»´æŒç§¯æçŠ¶æ€',
                'åˆ†äº«å¿«ä¹ç»éªŒ',
                'å»ºç«‹å¥åº·ä¹ æƒ¯',
                'ç›®æ ‡è®¾å®š'
            ],
            'calm': [
                'ä¿æŒå†…å¿ƒå¹³é™',
                'æ·±åº¦æ€è€ƒç»ƒä¹ ',
                'è‡ªæˆ‘åæ€',
                'æŒç»­æˆé•¿'
            ]
        }

        return challenges.get(emotion, ['åŸºç¡€è®¤çŸ¥è®­ç»ƒ'])

    def analyze_with_chatglm_dual(self, emotions, trigger_event, intensity, content):
        """
        ä½¿ç”¨ChatGLMåŒè°ƒç”¨ï¼šå¹¶è¡Œè·å–ç”¨æˆ·å‹å¥½ç‰ˆå’Œæ¸¸æˆæ•°å€¼ç‰ˆ
        è¿”å›: (user_message, game_data)
        """
        if not self.zhipu_client:
            print("[è­¦å‘Š] ChatGLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ", file=sys.stderr)
            return self._fallback_dual_analysis(emotions, trigger_event, intensity, content)

        # å‡†å¤‡ä¸¤ä¸ªPrompt
        if get_user_friendly_prompt and get_game_data_prompt:
            prompt_user = get_user_friendly_prompt(emotions, trigger_event, intensity, content)
            prompt_game = get_game_data_prompt(emotions, trigger_event, intensity, content)
        else:
            # å¦‚æœPromptæ¨¡å—åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨å†…ç½®Prompt
            prompt_user = self._get_default_user_prompt(emotions, trigger_event, intensity, content)
            prompt_game = self._get_default_game_prompt(emotions, trigger_event, intensity, content)

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œè°ƒç”¨
        with ThreadPoolExecutor(max_workers=2) as executor:
            # æäº¤ä¸¤ä¸ªä»»åŠ¡
            print(f"[è°ƒè¯•] å‡†å¤‡è°ƒç”¨ç”¨æˆ·å‹å¥½ç‰ˆ: max_tokens=1500, temp=0.8", file=sys.stderr)
            print(f"[è°ƒè¯•] ç”¨æˆ·å‹å¥½ç‰ˆPromptå‰50å­—ç¬¦: {prompt_user[:50]}...", file=sys.stderr)

            future_user = executor.submit(
                self._call_chatglm_single,
                prompt_user,
                max_tokens=1500,
                temperature=0.8  # ç”¨æˆ·ç‰ˆæ›´æ¸©æš–
            )

            print(f"[è°ƒè¯•] å‡†å¤‡è°ƒç”¨æ¸¸æˆæ•°æ®ç‰ˆ: max_tokens=4000, temp=0.3", file=sys.stderr)
            print(f"[è°ƒè¯•] æ¸¸æˆæ•°æ®ç‰ˆPromptå‰50å­—ç¬¦: {prompt_game[:50]}...", file=sys.stderr)

            future_game = executor.submit(
                self._call_chatglm_single,
                prompt_game,
                max_tokens=4000,  # å¢åŠ åˆ°4000ç¡®ä¿JSONå®Œæ•´
                temperature=0.3  # æ•°æ®ç‰ˆæ›´ç²¾ç¡®
            )

            # ç­‰å¾…ç»“æœ
            user_message = None
            game_data = None

            for future in as_completed([future_user, future_game]):
                if future == future_user:
                    try:
                        user_message = future.result()
                    except Exception as e:
                        print(f"[é”™è¯¯] ç”¨æˆ·å‹å¥½ç‰ˆè°ƒç”¨å¤±è´¥: {e}", file=sys.stderr)
                        user_message = "æŠ±æ­‰ï¼ŒAIåˆ†ææš‚æ—¶ä¸å¯ç”¨ï¼Œä½†ä½ çš„æ—¥è®°å·²ç»å®‰å…¨ä¿å­˜äº†ã€‚"

                elif future == future_game:
                    try:
                        game_data_raw = future.result()
                        # è§£æJSON
                        game_data = self._parse_game_data_json(game_data_raw)
                    except Exception as e:
                        print(f"[é”™è¯¯] æ¸¸æˆæ•°æ®ç‰ˆè°ƒç”¨å¤±è´¥: {e}", file=sys.stderr)
                        game_data = None

        # å¦‚æœæ¸¸æˆæ•°æ®è§£æå¤±è´¥ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ
        if not game_data:
            game_data = self._fallback_game_data(emotions, trigger_event, intensity, content)

        return user_message, game_data

    def _call_chatglm_single(self, prompt, max_tokens=2000, temperature=0.7):
        """å•æ¬¡ChatGLMè°ƒç”¨"""
        try:
            system_prompt = get_system_prompt() if get_system_prompt else "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„CBTåˆ†æå¸ˆã€‚"

            # åˆ¤æ–­è°ƒç”¨ç±»å‹ï¼ˆæ ¹æ®å‚æ•°ï¼‰
            call_type = "ç”¨æˆ·å‹å¥½ç‰ˆ" if max_tokens == 1500 else "æ¸¸æˆæ•°æ®ç‰ˆ" if max_tokens == 4000 else f"æœªçŸ¥({max_tokens})"
            print(f"[è°ƒè¯•] å¼€å§‹{call_type}è°ƒç”¨ChatGLMï¼Œæ¨¡å‹: {self.zhipu_model}, max_tokens: {max_tokens}, temp: {temperature}", file=sys.stderr)

            response = self.zhipu_client.chat.completions.create(
                model=self.zhipu_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                stream=False,
                max_tokens=max_tokens,
                temperature=temperature
            )

            content = response.choices[0].message.content
            print(f"[è°ƒè¯•] {call_type}å“åº”é•¿åº¦: {len(content) if content else 0} å­—ç¬¦", file=sys.stderr)
            if content:
                print(f"[è°ƒè¯•] {call_type}å“åº”å‰100å­—ç¬¦: {content[:100]}...", file=sys.stderr)

            return content

        except Exception as e:
            print(f"[é”™è¯¯] ChatGLM APIè°ƒç”¨å¤±è´¥: {e}", file=sys.stderr)
            import traceback
            traceback.print_exc(file=sys.stderr)
            raise

    def _parse_game_data_json(self, json_string):
        """è§£ææ¸¸æˆæ•°æ®JSON"""
        try:
            # æ£€æŸ¥è¾“å…¥æ˜¯å¦ä¸ºç©º
            if not json_string or not json_string.strip():
                print(f"[é”™è¯¯] ChatGLMè¿”å›ç©ºå“åº”", file=sys.stderr)
                return None

            # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
            cleaned = re.sub(r'```json\s*|\s*```', '', json_string).strip()

            # è®°å½•æ¸…ç†åçš„å†…å®¹ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            if len(cleaned) < 50:
                print(f"[è°ƒè¯•] æ¸…ç†åå†…å®¹å¤ªçŸ­: {cleaned}", file=sys.stderr)
                return None

            # å°è¯•è§£æJSON
            data = json.loads(cleaned)

            # éªŒè¯å¿…è¦å­—æ®µ
            required_keys = ['emotion_analysis', 'game_values']
            for key in required_keys:
                if key not in data:
                    print(f"[è­¦å‘Š] ç¼ºå°‘å¿…è¦å­—æ®µ: {key}ï¼Œå°è¯•ä½¿ç”¨é™çº§æ–¹æ¡ˆ", file=sys.stderr)
                    return None

            print(f"[æˆåŠŸ] æ¸¸æˆæ•°æ®JSONè§£ææˆåŠŸ", file=sys.stderr)
            return data

        except json.JSONDecodeError as e:
            print(f"[é”™è¯¯] JSONè§£æå¤±è´¥: {e}", file=sys.stderr)
            # å®‰å…¨åœ°æ‰“å°åŸå§‹å†…å®¹
            if json_string:
                preview = json_string[:300] if len(json_string) > 300 else json_string
                print(f"åŸå§‹å†…å®¹å‰300å­—ç¬¦: {preview}", file=sys.stderr)
            else:
                print(f"åŸå§‹å†…å®¹ä¸ºç©ºæˆ–None", file=sys.stderr)
            return None
        except Exception as e:
            print(f"[é”™è¯¯] æ•°æ®éªŒè¯å¤±è´¥: {e}", file=sys.stderr)
            return None

    def _fallback_dual_analysis(self, emotions, trigger_event, intensity, content):
        """é™çº§æ–¹æ¡ˆï¼šå½“ChatGLMä¸å¯ç”¨æ—¶"""
        user_message = f"""æ„Ÿè°¢ä½ è®°å½•ä»Šå¤©çš„æƒ…ç»ªã€‚

æˆ‘æ³¨æ„åˆ°ä½ æ„Ÿå—åˆ°äº†{', '.join(emotions)}ï¼Œæƒ…ç»ªå¼ºåº¦è¾¾åˆ°äº†{intensity}/10ã€‚è¿™ç§æ„Ÿå—åœ¨ç»å†"{trigger_event}"ä¹‹åæ˜¯å®Œå…¨æ­£å¸¸çš„ã€‚

è™½ç„¶AIåˆ†ææš‚æ—¶ä¸å¯ç”¨ï¼Œä½†è¯·è®°ä½ï¼š
1. è®°å½•æƒ…ç»ªæœ¬èº«å°±æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å¼€å§‹
2. è®¤è¯†åˆ°è‡ªå·±çš„æ„Ÿå—æ˜¯æ”¹å˜çš„ç¬¬ä¸€æ­¥
3. ç»§ç»­åšæŒè®°å½•ï¼Œä½ ä¼šçœ‹åˆ°è¿›æ­¥

åŠ æ²¹ï¼ğŸ’ª"""

        game_data = self._fallback_game_data(emotions, trigger_event, intensity, content)

        return user_message, game_data

    def _fallback_game_data(self, emotions, trigger_event, intensity, content):
        """é™çº§æ–¹æ¡ˆï¼šç”ŸæˆåŸºç¡€æ¸¸æˆæ•°æ®"""
        # ç®€å•åˆ†ç±»æ­£è´Ÿé¢æƒ…ç»ª
        positive_emotions = ['å¼€å¿ƒ', 'å¹³é™', 'æ¸©æš–', 'å…´å¥‹', 'æ»¡è¶³']
        negative_emotions = ['ç„¦è™‘', 'æ„¤æ€’', 'æ‚²ä¼¤', 'æ²®ä¸§', 'å®³æ€•', 'å­¤ç‹¬']

        pos_count = sum(1 for e in emotions if e in positive_emotions)
        neg_count = sum(1 for e in emotions if e in negative_emotions)

        emotion_balance = (pos_count - neg_count) / max(len(emotions), 1)
        emotion_intensity_normalized = intensity / 10.0

        # è®¡ç®—æ¸¸æˆæ•°å€¼
        mental_health = max(0, min(100, int(100 - (emotion_intensity_normalized * 100) + (emotion_balance * 20))))
        stress_level = int(emotion_intensity_normalized * 100)
        income_multiplier = max(0.5, min(2.0, 1.0 + (emotion_balance * 0.5)))

        return {
            "emotion_analysis": {
                "primary_emotion": emotions[0] if emotions else "å¹³é™",
                "emotion_intensity": emotion_intensity_normalized,
                "positive_emotions": [e for e in emotions if e in positive_emotions],
                "negative_emotions": [e for e in emotions if e in negative_emotions],
                "emotion_balance": emotion_balance
            },
            "cbt_insights": {
                "cognitive_distortions": [],
                "core_beliefs": [],
                "automatic_thoughts": []
            },
            "game_values": {
                "mental_health_score": mental_health,
                "stress_level": stress_level,
                "growth_potential": 50,
                "daily_income_base": 100,
                "income_multiplier": income_multiplier,
                "energy_level": max(0, 100 - stress_level),
                "mood_bonus": int((emotion_balance * 50))
            },
            "challenges": [],
            "recommendations": {
                "suggested_game": "åŸºç¡€æƒ…ç»ªç®¡ç†",
                "difficulty_level": max(1, min(5, int(emotion_intensity_normalized * 5))),
                "focus_areas": ["æƒ…ç»ªè¯†åˆ«", "è‡ªæˆ‘å…³æ€€"]
            }
        }

    def _get_default_user_prompt(self, emotions, trigger_event, intensity, content):
        """é»˜è®¤çš„ç”¨æˆ·å‹å¥½Prompt"""
        return f"""ä½ æ˜¯ä¸€ä½æ¸©æš–çš„å¿ƒç†å’¨è¯¢å¸ˆã€‚ç”¨æˆ·è®°å½•äº†æƒ…ç»ªæ—¥è®°ï¼Œè¯·ç»™äºˆæ¸©æš–çš„å›åº”å’ŒCBTåˆ†æã€‚

æƒ…ç»ª: {', '.join(emotions)}
è§¦å‘äº‹ä»¶: {trigger_event}
å¼ºåº¦: {intensity}/10
å†…å®¹: {content}

è¯·ç”¨æ¸©æš–ã€é¼“åŠ±çš„è¯­æ°”å›å¤ï¼ŒåŒ…æ‹¬ï¼š
1. è‚¯å®šç”¨æˆ·è®°å½•æƒ…ç»ªçš„å‹‡æ°”
2. è¯†åˆ«ä¸»è¦æƒ…ç»ªå’Œå¯èƒ½çš„è®¤çŸ¥æ‰­æ›²
3. æä¾›3-4æ¡å…·ä½“çš„CBTå»ºè®®
4. ç»™äºˆå¸Œæœ›å’Œæ”¯æŒ"""

    def _get_default_game_prompt(self, emotions, trigger_event, intensity, content):
        """é»˜è®¤çš„æ¸¸æˆæ•°æ®Prompt"""
        return f"""è¯·åˆ†æä»¥ä¸‹æƒ…ç»ªæ—¥è®°å¹¶è¿”å›JSONæ ¼å¼çš„æ¸¸æˆæ•°å€¼ã€‚

æƒ…ç»ª: {', '.join(emotions)}
è§¦å‘äº‹ä»¶: {trigger_event}
å¼ºåº¦: {intensity}/10
å†…å®¹: {content}

è¿”å›JSONæ ¼å¼ï¼ˆä¸è¦markdownï¼‰ï¼š
{{
    "emotion_analysis": {{...}},
    "game_values": {{
        "mental_health_score": 0-100,
        "stress_level": 0-100,
        "daily_income_base": æ•´æ•°,
        "income_multiplier": å°æ•°
    }}
}}"""

    def analyze_cbt_content(self, diary_id, content, emotions, trigger_event, intensity):
        """
        ä½¿ç”¨ChatGLMåŒè°ƒç”¨åˆ†ææ—¥è®°
        è¿”å›åŒ…å«ç”¨æˆ·æ¶ˆæ¯å’Œæ¸¸æˆæ•°å€¼çš„å®Œæ•´åˆ†æç»“æœ
        """
        try:
            print(f"[å¼€å§‹] åˆ†ææ—¥è®° ID={diary_id}", file=sys.stderr)

            # ä½¿ç”¨æ–°çš„åŒè°ƒç”¨æ–¹æ³•
            user_message, game_data = self.analyze_with_chatglm_dual(
                emotions=emotions or [],
                trigger_event=trigger_event or '',
                intensity=intensity,
                content=content
            )

            # æ„å»ºè¿”å›ç»“æœï¼ˆå…¼å®¹å‰ç«¯æœŸæœ›çš„æ ¼å¼ï¼‰
            analysis_result = {
                # Part 1: ç»™ç”¨æˆ·çœ‹çš„æ¸©æš–æ¶ˆæ¯
                "user_message": user_message,

                # Part 2: æ¸¸æˆæ•°å€¼ï¼ˆä»game_dataæå–ï¼‰
                "overall_emotion": game_data['emotion_analysis']['primary_emotion'],
                "emotion_intensity": game_data['emotion_analysis']['emotion_intensity'],
                "cognitive_distortions": game_data.get('cbt_insights', {}).get('cognitive_distortions', []),
                "suggestions": self._extract_suggestions_from_user_message(user_message),
                "recommended_game": game_data.get('recommendations', {}).get('suggested_game', 'åŸºç¡€æƒ…ç»ªç®¡ç†'),

                # Part 3: æ¸¸æˆæ•°å€¼ï¼ˆæ–°å¢ï¼‰
                "game_values": game_data['game_values'],
                "emotion_analysis": game_data['emotion_analysis'],
                "challenges": game_data.get('challenges', []),
                "recommendations": game_data.get('recommendations', {}),

                # å…ƒæ•°æ®
                "ai_model_version": f"chatglm-{self.zhipu_model}",
                "analysis_timestamp": datetime.utcnow().isoformat()
            }

            # ä¿å­˜åˆ°æ•°æ®åº“
            self._save_analysis_result(diary_id, analysis_result)

            print(f"[æˆåŠŸ] æ—¥è®°åˆ†æå®Œæˆ ID={diary_id}", file=sys.stderr)
            return analysis_result

        except Exception as e:
            print(f"[é”™è¯¯] CBTåˆ†æå¤±è´¥: {e}", file=sys.stderr)
            import traceback
            traceback.print_exc()

            # ä½¿ç”¨é™çº§æ–¹æ¡ˆ
            user_message, game_data = self._fallback_dual_analysis(emotions, trigger_event, intensity, content)

            return {
                "user_message": user_message,
                "overall_emotion": game_data['emotion_analysis']['primary_emotion'],
                "emotion_intensity": game_data['emotion_analysis']['emotion_intensity'],
                "cognitive_distortions": [],
                "suggestions": ["ç»§ç»­è®°å½•æƒ…ç»ª", "å…³æ³¨ç§¯æçš„ä¸€é¢", "å¯»æ±‚æ”¯æŒ"],
                "recommended_game": game_data.get('recommendations', {}).get('suggested_game'),
                "game_values": game_data['game_values'],
                "emotion_analysis": game_data['emotion_analysis'],
                "challenges": [],
                "recommendations": game_data.get('recommendations', {}),
                "ai_model_version": "fallback",
                "analysis_timestamp": datetime.utcnow().isoformat()
            }

    def _extract_suggestions_from_user_message(self, user_message):
        """ä»ç”¨æˆ·æ¶ˆæ¯ä¸­æå–å»ºè®®åˆ—è¡¨"""
        # ç®€å•çš„æ­£åˆ™æå–ï¼ˆå‡è®¾æ¶ˆæ¯ä¸­æœ‰ç¼–å·åˆ—è¡¨ï¼‰
        suggestions = []
        import re
        # åŒ¹é… "1. xxx" æˆ– "- xxx" æ ¼å¼çš„åˆ—è¡¨
        patterns = [
            r'\d+\.\s*(.+?)(?=\n|$)',  # 1. å»ºè®®
            r'-\s*(.+?)(?=\n|$)',       # - å»ºè®®
            r'â€¢\s*(.+?)(?=\n|$)'        # â€¢ å»ºè®®
        ]

        for pattern in patterns:
            matches = re.findall(pattern, user_message)
            if matches:
                suggestions.extend([m.strip() for m in matches[:5]])  # æœ€å¤š5æ¡
                break

        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œè¿”å›é»˜è®¤å»ºè®®
        if not suggestions:
            suggestions = [
                "ç»§ç»­è®°å½•ä½ çš„æƒ…ç»ªå’Œæƒ³æ³•",
                "å°è¯•è¯†åˆ«è§¦å‘æƒ…ç»ªçš„å…·ä½“æƒ³æ³•",
                "ç»™è‡ªå·±ä¸€äº›å…³æ€€å’Œæ—¶é—´"
            ]

        return suggestions[:5]  # æœ€å¤šè¿”å›5æ¡

    def _call_qwen_cbt_analysis(self, prompt):
        """è°ƒç”¨QWENè¿›è¡ŒCBTåˆ†æ"""
        headers = {
            'Authorization': f'Bearer {self.qwen_api_key}',
            'Content-Type': 'application/json'
        }

        payload = {
            'model': self.qwen_model,
            'input': {
                'messages': [
                    {
                        'role': 'system',
                        'content': 'ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è®¤çŸ¥è¡Œä¸ºæ²»ç–—(CBT)åˆ†æå¸ˆï¼Œæ“…é•¿è¯†åˆ«è®¤çŸ¥æ‰­æ›²å¹¶æä¾›å»ºè®¾æ€§å»ºè®®ã€‚'
                    },
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ]
            },
            'parameters': {
                'result_format': 'message'
            }
        }

        response = requests.post(
            'https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation',
            headers=headers,
            json=payload,
            timeout=30
        )

        if response.status_code == 200:
            result = response.json()
            content = result.get('output', {}).get('choices', [{}])[0].get('message', {}).get('content', '')

            # è§£æJSONå“åº”
            import json
            import re
            # å°è¯•æå–JSON
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())

        return None

    def _call_coze_cbt_analysis(self, prompt):
        """è°ƒç”¨COZEè¿›è¡ŒCBTåˆ†æ"""
        headers = {
            'Authorization': f'Bearer {self.coze_api_key}',
            'Content-Type': 'application/json'
        }

        payload = {
            'bot_id': self.coze_bot_id,
            'user_id': 'cbt_diary_user',
            'query': prompt,
            'stream': False
        }

        response = requests.post(
            f'{self.coze_base_url}/v1/chat/completions',
            headers=headers,
            json=payload,
            timeout=30
        )

        if response.status_code == 200:
            result = response.json()
            # è§£æCOZEå“åº”ï¼ˆæ ¹æ®å®é™…APIå“åº”ç»“æ„è°ƒæ•´ï¼‰
            import json
            import re
            content = str(result)
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())

        return None

    def _build_traditional_cbt_prompt(self, payload):
        emotions = ', '.join(payload.get('emotions') or []) or 'æœªæŒ‡å®š'
        trigger_event = payload.get('trigger_event') or 'æœªæè¿°'
        intensity = payload.get('intensity') or 5
        content = payload.get('content') or ''
        return f"""
ä½ æ˜¯ä¸€åèµ„æ·±è®¤çŸ¥è¡Œä¸ºæ²»ç–—(CBT)æ²»ç–—å¸ˆï¼Œè¯·åŸºäºæ¥è®¿è€…çš„æ—¥è®°ç»™å‡ºç»“æ„åŒ–åˆ†æã€‚

**æƒ…ç»ªæ ‡ç­¾**ï¼š{emotions}
**è§¦å‘äº‹ä»¶**ï¼š{trigger_event}
**æƒ…ç»ªå¼ºåº¦**ï¼š{intensity}/10
**æ—¥è®°æ­£æ–‡**ï¼š
{content}

è¯·ä½¿ç”¨JSONè¾“å‡ºï¼Œå­—æ®µåŒ…å«ï¼š
{{
    "overall_emotion": "ä¸»è¦æƒ…ç»ª",
    "emotion_intensity": 0-1ä¹‹é—´çš„å°æ•°ï¼Œ
    "confidence_score": 0-1ä¹‹é—´çš„å°æ•°ï¼Œ
    "cognitive_distortions": [
        {{"type": "æ­ªæ›²ç±»å‹", "description": "è§£é‡Š"}}
    ],
    "core_beliefs": ["æ½œåœ¨ä¿¡å¿µ1", "æ½œåœ¨ä¿¡å¿µ2"],
    "automatic_thoughts": ["è‡ªåŠ¨æ€ç»´1", "è‡ªåŠ¨æ€ç»´2"],
    "suggestions": ["è®¤çŸ¥é‡æ„å»ºè®®1", "å»ºè®®2"],
    "recommended_game": "ç»“åˆæƒ…ç»ªçš„æ¸¸æˆ/ä»»åŠ¡å»ºè®®",
    "emotion_panel": {{
        "valence_score": -1åˆ°1çš„æ•°å€¼,
        "trigger_summary": "ç”¨1-2å¥æ€»ç»“å‘ç”Ÿäº†ä»€ä¹ˆ",
        "key_findings": ["è§‚å¯Ÿ1", "è§‚å¯Ÿ2"]
    }},
    "game_projection": {{
        "income_modifier": -1åˆ°1,
        "customer_flow_modifier": -1åˆ°1,
        "staff_morale_modifier": -1åˆ°1,
        "event_suggestion": "å¯è§¦å‘çš„ç»è¥äº‹ä»¶"
    }},
    "ai_companion": {{
        "message": "ç”¨ç¬¬ä¸€äººç§°å®‰æŠšè¯­",
        "follow_up_question": "ç»§ç»­å¯¹è¯çš„é—®é¢˜",
        "affirmation": "é¼“åŠ±è¯­"
    }},
    "coping_tips": ["å°è´´å£«1", "å°è´´å£«2"]
}}
"""

    def _call_zhipu_cbt_analysis(self, payload):
        """è°ƒç”¨æ™ºè°±GLMåˆ†ææ—¥è®°ï¼Œè¿”å›ç»“æ„åŒ–JSON"""
        if not self.zhipu_client:
            return None

        user_prompt = self._build_traditional_cbt_prompt(payload)
        try:
            response = self.zhipu_client.chat.completions.create(
                model=self.zhipu_model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯èµ„æ·±CBTæ²»ç–—å¸ˆå…¼æ¨¡æ‹Ÿç»è¥æ¸¸æˆè®¾è®¡å¸ˆï¼Œè¯·è¾“å‡ºç»“æ„åŒ–JSONï¼Œè¯­è¨€ä¿æŒä¸­æ–‡ã€‚"
                    },
                    {"role": "user", "content": user_prompt}
                ],
                thinking={"type": "enabled"},
                stream=False,
                temperature=0.6,
                max_tokens=2048
            )
        except Exception as exc:
            print(f"è°ƒç”¨æ™ºè°±GLMå¤±è´¥: {exc}")
            return None

        if not response or not getattr(response, 'choices', None):
            return None

        content = response.choices[0].message.content

        if isinstance(content, list):
            parsed_text = ''.join(
                part.get('text', '') if isinstance(part, dict) else str(part)
                for part in content
            )
        else:
            parsed_text = content

        return self._parse_json_response(parsed_text)

    def _parse_json_response(self, raw_text):
        if not raw_text:
            return None

        if isinstance(raw_text, (list, tuple)):
            raw_text = ''.join(str(item) for item in raw_text)

        try:
            return json.loads(raw_text)
        except (json.JSONDecodeError, TypeError):
            match = re.search(r'\{.*\}', str(raw_text), re.DOTALL)
            if match:
                try:
                    return json.loads(match.group())
                except json.JSONDecodeError:
                    return None
        return None

    def _ensure_panel_defaults(self, analysis_data, payload):
        analysis_data = analysis_data or {}
        fallback_emotion = payload.get('emotions', [None])[0] or 'neutral'
        analysis_data.setdefault('overall_emotion', fallback_emotion)
        raw_intensity = analysis_data.get('emotion_intensity')
        if raw_intensity is None:
            raw_intensity = max(1, min(int(payload.get('intensity') or 5), 10)) / 10.0
        analysis_data['emotion_intensity'] = float(raw_intensity)
        analysis_data.setdefault('confidence_score', 0.75)
        analysis_data.setdefault('cognitive_distortions', [])
        analysis_data.setdefault('core_beliefs', [])
        analysis_data.setdefault('automatic_thoughts', [])
        analysis_data.setdefault('suggestions', [])
        analysis_data.setdefault('recommended_game', 'æ€ç»´è§‰å¯Ÿè®­ç»ƒ')
        analysis_data.setdefault('coping_tips', analysis_data['suggestions'][:3])

        panel = analysis_data.get('emotion_panel') or {}
        panel.setdefault('overall_emotion', analysis_data['overall_emotion'])
        panel_intensity = panel.get('emotion_intensity')
        if panel_intensity is None:
            panel_intensity = analysis_data['emotion_intensity']
        panel['emotion_intensity'] = float(min(max(panel_intensity, 0.0), 1.0))
        base_valence = panel.get('valence_score')
        if base_valence is None:
            base_valence = self._emotion_to_valence(panel.get('overall_emotion'))
        panel['valence_score'] = round(base_valence, 3)
        panel['impact_score'] = round(panel['valence_score'] * panel['emotion_intensity'], 3)
        panel.setdefault('trigger_summary', payload.get('trigger_event') or 'æœªæè¿°å…·ä½“è§¦å‘äº‹ä»¶')
        panel.setdefault('key_findings', [])
        analysis_data['emotion_panel'] = panel

        projection = analysis_data.get('game_projection')
        analysis_data['game_projection'] = self._normalize_projection(projection, panel)

        if not analysis_data.get('ai_companion'):
            analysis_data['ai_companion'] = {
                'message': f"æˆ‘å¬è§ä½ æ­£ç»å†{panel.get('overall_emotion', 'å¤æ‚æƒ…ç»ª')}ï¼Œè°¢è°¢ä½ è®°å½•ä¸‹æ¥ï¼Œæˆ‘ä»¬ä¸€èµ·æƒ³æƒ³å¯ä»¥æ€ä¹ˆç…§é¡¾è‡ªå·±ã€‚",
                'follow_up_question': 'æ­¤åˆ»æœ€å¸Œæœ›å¾—åˆ°å“ªä¸€ç§æ”¯æŒï¼Ÿ',
                'affirmation': 'æ¯ä¸€æ¬¡è®°å½•éƒ½åœ¨å¸®åŠ©è‡ªå·±å‰è¿›ã€‚'
            }

        if not analysis_data.get('key_words'):
            analysis_data['key_words'] = self.extract_keywords(payload.get('content', ''))

        return analysis_data

    def _normalize_projection(self, projection, panel):
        projection = projection or {}
        valence = panel.get('valence_score', 0)
        intensity = panel.get('emotion_intensity', 0.5)

        def clamp(value):
            try:
                return max(-1.0, min(float(value), 1.0))
            except (TypeError, ValueError):
                return 0.0

        default_projection = self._calculate_game_projection(panel)

        return {
            'income_modifier': clamp(projection.get('income_modifier', default_projection['income_modifier'])),
            'customer_flow_modifier': clamp(projection.get('customer_flow_modifier', default_projection['customer_flow_modifier'])),
            'staff_morale_modifier': clamp(projection.get('staff_morale_modifier', default_projection['staff_morale_modifier'])),
            'event_suggestion': projection.get('event_suggestion') or self._event_from_valence(valence, intensity)
        }

    def _calculate_game_projection(self, panel):
        intensity = panel.get('emotion_intensity', 0.5)
        valence = panel.get('valence_score', 0.0)
        impact = valence * intensity

        return {
            'income_modifier': round(impact, 3),
            'customer_flow_modifier': round(impact * 0.7, 3),
            'staff_morale_modifier': round(impact * 0.5, 3),
            'event_suggestion': self._event_from_valence(valence, intensity)
        }

    def _emotion_to_valence(self, emotion):
        if not emotion:
            return 0.0
        mapping = {
            'happy': 0.8,
            'joy': 0.7,
            'calm': 0.4,
            'grateful': 0.6,
            'excited': 0.7,
            'neutral': 0.0,
            'anxious': -0.5,
            'sad': -0.7,
            'angry': -0.8,
            'frustrated': -0.6,
            'fear': -0.7,
            'lonely': -0.6
        }
        return mapping.get(str(emotion).lower(), 0.0)

    def _event_from_valence(self, valence, intensity):
        if valence >= 0.4:
            return 'ä¸¾åŠèŠ‚æ—¥è¥é”€æ´»åŠ¨ï¼Œæ”¾å¤§ç§¯ææƒ…ç»ª'
        if valence >= 0.1:
            return 'æ¨å‡ºå°å‹é™æ—¶ä¼˜æƒ ï¼Œå·©å›ºç¨³å®šçŠ¶æ€'
        if valence <= -0.6:
            return 'å¯åŠ¨ã€Œæƒ…ç»ªä¿®å¤å‘¨ã€ï¼Œè°ƒä½è¥ä¸šå¼ºåº¦'
        if valence <= -0.2:
            return 'å¼€æ”¾å‘˜å·¥å…³æ€€æ—¥ï¼Œé¼“åŠ±æ…¢ä¸‹æ¥'
        return 'ä¿æŒæ—¥å¸¸ç»è¥ï¼Œå…³æ³¨å¾®å°æ³¢åŠ¨'

    def _fallback_cbt_analysis(self, content, emotions, intensity, trigger_event=''):
        """æœ¬åœ°å…œåº•é€»è¾‘ï¼Œå½“LLMä¸å¯ç”¨æ—¶æä¾›åŸºç¡€CBTå»ºè®®"""
        distortions = []

        if any(word in content for word in ['æ€»æ˜¯', 'æ°¸è¿œ', 'ä¸€å®š', 'å¿…é¡»']):
            distortions.append({
                'type': 'ç»å¯¹åŒ–æ€ç»´',
                'description': 'å®¹æ˜“æŠŠäº‹ä»¶æ”¾å¤§åˆ°â€œæ°¸è¿œâ€æˆ–â€œä¸€å®šâ€çš„ç¨‹åº¦'
            })

        if any(word in content for word in ['å…¨éƒ½', 'ä¸€æ— æ˜¯å¤„', 'æ²¡æ•‘']):
            distortions.append({
                'type': 'éé»‘å³ç™½',
                'description': 'å€¾å‘ç”¨æç«¯è§’åº¦è¯„ä»·è‡ªå·±æˆ–ä»–äºº'
            })

        if any(word in content for word in ['å¤±è´¥', 'å´©æºƒ', 'ç³Ÿç³•']):
            distortions.append({
                'type': 'ç¾éš¾åŒ–',
                'description': 'ä¹ æƒ¯é¢„æœŸäº‹æƒ…æœæœ€åæ–¹å‘å‘å±•'
            })

        suggestions = [
            'æŠŠæƒ…ç»ªå’Œäº‹å®æ‹†å¼€ï¼ŒæŠŠå…·ä½“äº‹ä»¶å†™æ¸…æ¥š',
            'åˆ—å‡ºæ”¯æŒä¸åå¯¹è¿™äº›è‡ªåŠ¨æƒ³æ³•çš„è¯æ®',
            'æƒ³è±¡æœ‹å‹é‡åˆ°ç›¸åŒæƒ…å†µï¼Œä½ ä¼šç»™TAä»€ä¹ˆå»ºè®®',
            'ç”¨3åˆ†é’Ÿåšä¸€æ¬¡å‘¼å¸æ‰«æï¼Œå›åˆ°å½“ä¸‹'
        ]

        main_emotion = emotions[0] if emotions else 'neutral'
        normalized_intensity = max(1, min(intensity or 5, 10)) / 10.0

        panel = {
            'overall_emotion': main_emotion,
            'emotion_intensity': normalized_intensity,
            'valence_score': self._emotion_to_valence(main_emotion),
            'trigger_summary': trigger_event or 'æœªè¯¦ç»†æè¿°è§¦å‘äº‹ä»¶',
            'key_findings': suggestions[:2]
        }

        return {
            'overall_emotion': main_emotion,
            'emotion_intensity': normalized_intensity,
            'cognitive_distortions': distortions if distortions else [{
                'type': 'éœ€è¦è¿›ä¸€æ­¥æ¢ç´¢',
                'description': 'å½“å‰æ–‡æœ¬å°šæ— æ³•å®šä½å…·ä½“çš„è®¤çŸ¥æ¨¡å¼ï¼Œå»ºè®®ç»§ç»­è®°å½•'
            }],
            'core_beliefs': [],
            'automatic_thoughts': [],
            'suggestions': suggestions,
            'recommended_game': 'æ€ç»´é‡æ„ç»ƒä¹ ',
            'emotion_panel': panel,
            'game_projection': self._calculate_game_projection(panel),
            'ai_companion': {
                'message': 'æˆ‘çœ‹åˆ°ä½ å·²ç»å‹‡æ•¢åœ°æŠŠæ„Ÿå—å†™ä¸‹æ¥ï¼Œæˆ‘ä»¬å°±ä»è¿™ä¸€æ­¥æ…¢æ…¢æ¥ã€‚',
                'follow_up_question': 'æœ€æƒ³å…ˆè°ƒæ•´çš„æ˜¯æƒ…ç»ªã€è¡Œä¸ºè¿˜æ˜¯æ€ç»´ï¼Ÿ',
                'affirmation': 'æ¯ä¸€æ¬¡è®°å½•éƒ½åœ¨è®­ç»ƒä½ çš„è‡ªæˆ‘è§‰å¯Ÿã€‚'
            },
            'coping_tips': suggestions[:3]
        }

    def _save_analysis_result(self, diary_id, analysis_data):
        """ä¿å­˜æƒ…ç»ªåˆ†æè®°å½•"""
        try:
            existing_analysis = EmotionAnalysis.query.filter_by(diary_id=diary_id).first()
            panel = analysis_data.get('emotion_panel', {})
            confidence = analysis_data.get('confidence_score', 0.8)
            keywords = analysis_data.get('key_words') or analysis_data.get('automatic_thoughts', [])
            model_version = analysis_data.get('ai_model_version', 'cbt-fallback')

            if existing_analysis:
                existing_analysis.overall_emotion = analysis_data.get('overall_emotion')
                existing_analysis.emotion_intensity = analysis_data.get('emotion_intensity')
                existing_analysis.emotion_dimensions = panel
                existing_analysis.key_words = keywords
                existing_analysis.confidence_score = confidence
                existing_analysis.analyzed_at = datetime.utcnow()
                existing_analysis.ai_model_version = model_version
                existing_analysis.analysis_payload = analysis_data
            else:
                new_analysis = EmotionAnalysis(
                    diary_id=diary_id,
                    overall_emotion=analysis_data.get('overall_emotion'),
                    emotion_intensity=analysis_data.get('emotion_intensity'),
                    emotion_dimensions=panel,
                    key_words=keywords,
                    confidence_score=confidence,
                    ai_model_version=model_version,
                    analysis_payload=analysis_data
                )
                db.session.add(new_analysis)

            db.session.commit()

        except Exception as e:
            print(f"ä¿å­˜åˆ†æç»“æœå¤±è´¥: {str(e)}")
            db.session.rollback()

emotion_service = EmotionAnalysisService()

@bp.route('/<int:diary_id>', methods=['POST'])
@jwt_required()
def analyze_diary(diary_id):
    """åˆ†æå•ç¯‡æ—¥è®°çš„æƒ…ç»ª"""
    try:
        user_id = get_jwt_identity()

        # éªŒè¯æ—¥è®°æ‰€æœ‰æƒ
        diary = EmotionDiary.query.filter_by(id=diary_id, user_id=user_id).first()
        if not diary:
            return jsonify({'error': 'Diary not found'}), 404

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰åˆ†æç»“æœ
        existing_analysis = EmotionAnalysis.query.filter_by(diary_id=diary_id).first()
        if existing_analysis:
            return jsonify({
                'message': 'Analysis already exists',
                'analysis': existing_analysis.to_dict()
            }), 200

        # è¿›è¡Œæƒ…ç»ªåˆ†æ
        text_content = diary.content

        # å°è¯•ä½¿ç”¨COZE API
        coze_result = emotion_service.analyze_with_coze(text_content)

        # å¦‚æœCOZEå¤±è´¥ï¼Œä½¿ç”¨QWEN
        if coze_result:
            analysis_result = coze_result
            ai_model_version = 'coze'
        else:
            qwen_result = emotion_service.analyze_with_qwen(text_content)
            if qwen_result:
                analysis_result = qwen_result
                ai_model_version = 'qwen'
            else:
                # å¦‚æœéƒ½å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨åˆ†æ
                analysis_result = emotion_service.parse_text_emotion(text_content)
                ai_model_version = 'fallback'

        if not analysis_result:
            return jsonify({'error': 'Failed to analyze emotion'}), 500

        # åˆ›å»ºåˆ†æè®°å½•
        analysis = EmotionAnalysis(
            diary_id=diary_id,
            overall_emotion=analysis_result.get('overall_emotion', 'neutral'),
            emotion_intensity=analysis_result.get('emotion_intensity', 0.5),
            emotion_dimensions=analysis_result.get('emotion_dimensions', {}),
            key_words=analysis_result.get('key_words', []),
            confidence_score=analysis_result.get('confidence_score', 0.5),
            ai_model_version=ai_model_version
        )

        db.session.add(analysis)

        # æ›´æ–°æ—¥è®°çš„åˆ†æçŠ¶æ€
        diary.analysis_status = 'completed'
        diary.emotion_score = {
            'overall_emotion': analysis_result.get('overall_emotion', 'neutral'),
            'emotion_intensity': analysis_result.get('emotion_intensity', 0.5),
            'confidence_score': analysis_result.get('confidence_score', 0.5)
        }

        db.session.commit()

        # ç”Ÿæˆæ¸¸æˆæ˜ å°„é…ç½®
        game_mapping = emotion_service.generate_emotion_mapping(analysis_result)

        return jsonify({
            'message': 'Emotion analysis completed',
            'analysis': analysis.to_dict(),
            'game_mapping': game_mapping
        }), 201

    except Exception as e:
        db.session.rollback()
        return jsonify({'error': f'Analysis failed: {str(e)}'}), 500

@bp.route('/batch', methods=['POST'])
@jwt_required()
def batch_analyze():
    """æ‰¹é‡åˆ†ææ—¥è®°"""
    try:
        user_id = get_jwt_identity()
        data = request.get_json()

        diary_ids = data.get('diary_ids', [])
        if not diary_ids:
            return jsonify({'error': 'No diary IDs provided'}), 400

        results = []
        for diary_id in diary_ids:
            # éªŒè¯æ—¥è®°æ‰€æœ‰æƒ
            diary = EmotionDiary.query.filter_by(id=diary_id, user_id=user_id).first()
            if not diary:
                results.append({'diary_id': diary_id, 'status': 'not_found'})
                continue

            # æ£€æŸ¥æ˜¯å¦å·²æœ‰åˆ†æç»“æœ
            existing_analysis = EmotionAnalysis.query.filter_by(diary_id=diary_id).first()
            if existing_analysis:
                results.append({
                    'diary_id': diary_id,
                    'status': 'already_analyzed',
                    'analysis': existing_analysis.to_dict()
                })
                continue

            # è¿›è¡Œæƒ…ç»ªåˆ†æï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…é¡¹ç›®ä¸­å¯ä»¥ä¼˜åŒ–ä¸ºå¼‚æ­¥å¤„ç†ï¼‰
            text_content = diary.content
            analysis_result = emotion_service.analyze_with_coze(text_content)

            if not analysis_result:
                analysis_result = emotion_service.analyze_with_qwen(text_content)

            if not analysis_result:
                analysis_result = emotion_service.parse_text_emotion(text_content)

            if analysis_result:
                # åˆ›å»ºåˆ†æè®°å½•
                analysis = EmotionAnalysis(
                    diary_id=diary_id,
                    overall_emotion=analysis_result.get('overall_emotion', 'neutral'),
                    emotion_intensity=analysis_result.get('emotion_intensity', 0.5),
                    emotion_dimensions=analysis_result.get('emotion_dimensions', {}),
                    key_words=analysis_result.get('key_words', []),
                    confidence_score=analysis_result.get('confidence_score', 0.5),
                    ai_model_version='batch_analysis'
                )

                db.session.add(analysis)

                # æ›´æ–°æ—¥è®°çŠ¶æ€
                diary.analysis_status = 'completed'
                diary.emotion_score = {
                    'overall_emotion': analysis_result.get('overall_emotion', 'neutral'),
                    'emotion_intensity': analysis_result.get('emotion_intensity', 0.5),
                    'confidence_score': analysis_result.get('confidence_score', 0.5)
                }

                results.append({
                    'diary_id': diary_id,
                    'status': 'analyzed',
                    'analysis': analysis.to_dict()
                })
            else:
                results.append({'diary_id': diary_id, 'status': 'analysis_failed'})

        db.session.commit()

        return jsonify({
            'message': 'Batch analysis completed',
            'results': results
        }), 200

    except Exception as e:
        db.session.rollback()
        return jsonify({'error': f'Batch analysis failed: {str(e)}'}), 500

@bp.route('/<int:diary_id>', methods=['GET'])
@jwt_required()
def get_analysis(diary_id):
    """è·å–æ—¥è®°çš„æƒ…ç»ªåˆ†æç»“æœ"""
    try:
        user_id = get_jwt_identity()

        # éªŒè¯æ—¥è®°æ‰€æœ‰æƒ
        diary = EmotionDiary.query.filter_by(id=diary_id, user_id=user_id).first()
        if not diary:
            return jsonify({'error': 'Diary not found'}), 404

        # è·å–åˆ†æç»“æœ
        analysis = EmotionAnalysis.query.filter_by(diary_id=diary_id).first()

        if not analysis:
            return jsonify({'error': 'Analysis not found'}), 404

        return jsonify({
            'analysis': analysis.to_dict()
        }), 200

    except Exception as e:
        return jsonify({'error': f'Failed to get analysis: {str(e)}'}), 500

@bp.route('/history', methods=['GET'])
@jwt_required()
def get_analysis_history():
    """è·å–ç”¨æˆ·çš„æƒ…ç»ªåˆ†æå†å²"""
    try:
        user_id = get_jwt_identity()
        page = request.args.get('page', 1, type=int)
        limit = request.args.get('limit', 20, type=int)

        # é™åˆ¶æ¯é¡µæ•°é‡
        limit = min(limit, 100)

        # æŸ¥è¯¢ç”¨æˆ·çš„åˆ†æå†å²
        query = db.session.query(EmotionAnalysis, EmotionDiary).join(
            EmotionDiary, EmotionAnalysis.diary_id == EmotionDiary.id
        ).filter(
            EmotionDiary.user_id == user_id
        ).order_by(EmotionAnalysis.analyzed_at.desc())

        # åˆ†é¡µ
        results = query.paginate(page=page, per_page=limit, error_out=False)

        analysis_list = []
        for analysis, diary in results.items:
            analysis_data = analysis.to_dict()
            analysis_data['diary_content'] = diary.content[:100] + '...' if len(diary.content) > 100 else diary.content
            analysis_list.append(analysis_data)

        return jsonify({
            'analysis_history': analysis_list,
            'pagination': {
                'page': results.page,
                'pages': results.pages,
                'per_page': results.per_page,
                'total': results.total,
                'has_prev': results.has_prev,
                'has_next': results.has_next
            }
        }), 200

    except Exception as e:
        return jsonify({'error': f'Failed to get analysis history: {str(e)}'}), 500



